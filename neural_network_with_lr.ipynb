{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaledaldhaheri91-maker/khaled1/blob/main/neural_network_with_lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3L5tbJcabR_"
      },
      "source": [
        "This is a great request. Drawing on the uses cases mentioned in the video sources, I will focus on the example of **e-commerce product recommendations** and generate synthetic data and corresponding TensorFlow/Keras code.\n",
        "\n",
        "The sources highlight that TensorFlow is an open-source library created by Google used to **build, train, and deploy** machine learning models at a massive scale. For beginners or general developers, the recommended path is using **Keras**, the user-friendly, high-level API built right on top of TensorFlow. The Keras workflow is simply three steps: define, compile, and train.\n",
        "\n",
        "## 1. Synthetic Large Data Creation: E-commerce Product Recommendations\n",
        "\n",
        "E-commerce sites use TensorFlow for product recommendations. To model this, we will create a dataset representing user interactions (ratings) with products. Since the query asks for \"synthetic large data,\" we will generate 100,000 interaction records.\n",
        "\n",
        "*Note: While the source material focuses on TensorFlow and Keras, standard Python libraries like `numpy` and `pandas` (which are not explicitly mentioned in the sources) are required to generate and structure this large synthetic dataset.*\n",
        "\n",
        "### Use Case: Simplified Collaborative Filtering Model\n",
        "\n",
        "We simulate data based on:\n",
        "1.  **Number of Users:** 1,000\n",
        "2.  **Number of Products:** 500\n",
        "3.  **Total Interactions (Ratings):** 100,000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bd1687d"
      },
      "source": [
        "## Notebook Roadmap\n",
        "\n",
        "To keep things clear, this notebook is structured into four main steps:\n",
        "\n",
        "1. **Generate synthetic recommendation data** (users, products, ratings).\n",
        "2. **Prepare train/test splits** that a real ML workflow would use.\n",
        "3. **Build a simple neural recommendation model in Keras** using embeddings.\n",
        "4. **Train the model with an explicit learning rate** and then **evaluate** it on unseen data.\n",
        "\n",
        "> Tip: Run the cells **from top to bottom** without skipping to avoid missing variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0hhYviyan7P",
        "outputId": "eb59c143-2950-4328-9847-b207579d66cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Synthetic Data for E-commerce Recommendations ---\n",
            "Total Interactions Generated: 100000 (Large Scale Data)\n",
            "   user_id  product_id  rating\n",
            "0      390         281       5\n",
            "1      424         202       2\n",
            "2      831         469       3\n",
            "3      567         199       5\n",
            "4      903          19       5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define parameters for 'large' synthetic data\n",
        "NUM_USERS = 1000\n",
        "NUM_PRODUCTS = 500\n",
        "NUM_INTERACTIONS = 100000\n",
        "\n",
        "# 1. Create Synthetic IDs\n",
        "# Generate a large array of random User IDs\n",
        "user_ids = np.random.randint(1, NUM_USERS + 1, NUM_INTERACTIONS)\n",
        "# Generate a large array of random Product IDs\n",
        "product_ids = np.random.randint(1, NUM_PRODUCTS + 1, NUM_INTERACTIONS)\n",
        "# Generate interaction ratings (e.g., 1 to 5 stars)\n",
        "ratings = np.random.randint(1, 6, NUM_INTERACTIONS)\n",
        "\n",
        "# 2. Structure the data into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'user_id': user_ids,\n",
        "    'product_id': product_ids,\n",
        "    'rating': ratings\n",
        "})\n",
        "\n",
        "# Display the size and a sample of the synthetic data\n",
        "print(f\"--- Synthetic Data for E-commerce Recommendations ---\")\n",
        "print(f\"Total Interactions Generated: {len(data)} (Large Scale Data)\")\n",
        "print(data.head())\n",
        "\n",
        "# 3. Prepare data for model training\n",
        "# Determine unique counts for embedding layers\n",
        "unique_users = data['user_id'].nunique()\n",
        "unique_products = data['product_id'].nunique()\n",
        "\n",
        "# Map IDs to contiguous integers starting from 0 (required for embeddings)\n",
        "user_map = {id: i for i, id in enumerate(data['user_id'].unique())}\n",
        "product_map = {id: i for i, id in enumerate(data['product_id'].unique())}\n",
        "\n",
        "data['user'] = data['user_id'].map(user_map)\n",
        "data['product'] = data['product_id'].map(product_map)\n",
        "\n",
        "# Define X (inputs) and y (target)\n",
        "X = data[['user', 'product']].values\n",
        "y = data['rating'].values\n",
        "\n",
        "# Split data into training and testing sets (standard preparation step)\n",
        "from sklearn.model_selection import train_test_split # Note: sklearn is not mentioned in sources\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract inputs for the model\n",
        "train_user_input = X_train[:, 0]\n",
        "train_product_input = X_train[:, 1]\n",
        "\n",
        "\n",
        "## 2. TensorFlow/Keras Code for the Recommendation Model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "Y0A5YxsaaRuL",
        "outputId": "fed65fe6-16c9-4f56-ec45-04ca5fd224f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using embedding size = 50\n",
            "Using learning rate  = 0.001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"simple_recommender_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"simple_recommender_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m50,050\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m25,050\u001b[0m │ product_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_vector         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_vector      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ product_embeddin… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_product_concat │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ user_vector[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ product_vector[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m6,464\u001b[0m │ user_product_con… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rating_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,050</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │ product_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_vector         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_vector      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ product_embeddin… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_product_concat │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ product_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │ user_product_con… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rating_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,677\u001b[0m (326.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,677</span> (326.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,677\u001b[0m (326.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,677</span> (326.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.8391 - mae: 1.7966 - val_loss: 2.0897 - val_mae: 1.2508\n",
            "Epoch 2/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.0118 - mae: 1.2242 - val_loss: 2.0582 - val_mae: 1.2384\n",
            "Epoch 3/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.9784 - mae: 1.2104 - val_loss: 2.0507 - val_mae: 1.2347\n",
            "Epoch 4/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.9700 - mae: 1.2079 - val_loss: 2.0493 - val_mae: 1.2336\n",
            "Epoch 5/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.9651 - mae: 1.2081 - val_loss: 2.0554 - val_mae: 1.2365\n",
            "Model training complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Step 2: Build & Train the Neural Recommendation Model ---\n",
        "\n",
        "# We assume the previous cell has already created:\n",
        "# - NUM_USERS, NUM_PRODUCTS          (overall dataset dimensions)\n",
        "# - train_user_input, train_product_input, y_train\n",
        "# - X_test, y_test                   (for final evaluation in the later cell)\n",
        "#\n",
        "# Here we focus on:\n",
        "# 1. Defining the model architecture.\n",
        "# 2. Choosing an optimizer and **learning rate**.\n",
        "# 3. Training the model while monitoring validation performance.\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Model Hyperparameters\n",
        "# ----------------------------\n",
        "\n",
        "EMBEDDING_SIZE = 50   # Size of the latent representation for users/products\n",
        "LEARNING_RATE = 0.001 # <<-- Key hyperparameter we are adding explicitly\n",
        "\n",
        "print(f\"Using embedding size = {EMBEDDING_SIZE}\")\n",
        "print(f\"Using learning rate  = {LEARNING_RATE}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Input & Embedding Layers\n",
        "# ----------------------------\n",
        "\n",
        "# Input layers (each interaction has exactly one user_id and one product_id)\n",
        "user_input = Input(shape=(1,), name=\"user_input\")\n",
        "product_input = Input(shape=(1,), name=\"product_input\")\n",
        "\n",
        "# Embedding layers learn a dense vector for each user and each product.\n",
        "# We add +1 to NUM_USERS / NUM_PRODUCTS so that the maximum ID is included safely.\n",
        "user_embedding = Embedding(\n",
        "    input_dim=NUM_USERS + 1,\n",
        "    output_dim=EMBEDDING_SIZE,\n",
        "    name=\"user_embedding\",\n",
        ")(user_input)\n",
        "\n",
        "product_embedding = Embedding(\n",
        "    input_dim=NUM_PRODUCTS + 1,\n",
        "    output_dim=EMBEDDING_SIZE,\n",
        "    name=\"product_embedding\",\n",
        ")(product_input)\n",
        "\n",
        "# Flatten the embeddings so we can concatenate them\n",
        "user_vec = Flatten(name=\"user_vector\")(user_embedding)\n",
        "product_vec = Flatten(name=\"product_vector\")(product_embedding)\n",
        "\n",
        "# Concatenate user and product representations\n",
        "concat = Concatenate(name=\"user_product_concat\")([user_vec, product_vec])\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Dense Layers (Prediction Head)\n",
        "# ----------------------------\n",
        "\n",
        "hidden = Dense(64, activation=\"relu\", name=\"dense_1\")(concat)\n",
        "hidden = Dense(32, activation=\"relu\", name=\"dense_2\")(hidden)\n",
        "\n",
        "# Final output layer: predict a single rating (regression)\n",
        "output = Dense(1, activation=\"linear\", name=\"rating_output\")(hidden)\n",
        "\n",
        "model = Model(inputs=[user_input, product_input], outputs=output, name=\"simple_recommender_model\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Compile the Model\n",
        "# ----------------------------\n",
        "\n",
        "# Adam optimizer with an explicit learning rate\n",
        "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"mse\",           # Mean Squared Error is a common loss for rating prediction\n",
        "    metrics=[\"mae\"]       # Track Mean Absolute Error as a human-friendly metric\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Train the Model\n",
        "# ----------------------------\n",
        "\n",
        "history = model.fit(\n",
        "    x=[train_user_input, train_product_input],  # Inputs\n",
        "    y=y_train,                                  # Target ratings\n",
        "    epochs=5,                                   # Number of passes over the training data\n",
        "    batch_size=256,\n",
        "    validation_split=0.1,                       # 10% of training data used for validation\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# You can inspect the training curves later via `history.history`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wajV_FMQbhan",
        "outputId": "3a1c7b9d-a908-455a-b790-4c5c6f73325c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Evaluation on Unseen Test Set ---\n",
            "Test Loss (Mean Squared Error): 2.0224\n",
            "Test Mean Absolute Error (MAE): 1.2239\n"
          ]
        }
      ],
      "source": [
        "# --- Step 4: Final Evaluation on Unseen Test Data ---\n",
        "\n",
        "print(\"\\n--- Model Evaluation on Unseen Test Set ---\")\n",
        "\n",
        "# Extract inputs for the model from X_test\n",
        "test_user_input = X_test[:, 0]\n",
        "test_product_input = X_test[:, 1]\n",
        "\n",
        "# The evaluation process assesses the performance of the trained model\n",
        "# on the independent dataset (X_test, y_test) that the model has never seen.\n",
        "results = model.evaluate(\n",
        "    x=[test_user_input, test_product_input], # Test input data\n",
        "    y=y_test,                                # Test target data\n",
        "    batch_size=256,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Extract and display the metrics defined during the compile step\n",
        "loss = results[0]\n",
        "mae = results[1] # Mean Absolute Error (the chosen evaluation metric)\n",
        "\n",
        "print(f\"Test Loss (Mean Squared Error): {loss:.4f}\")\n",
        "print(f\"Test Mean Absolute Error (MAE): {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpUXtiPGaV_v"
      },
      "source": [
        "### Enhancing Understanding\n",
        "\n",
        "TensorFlow provides an entire ecosystem. If we were to continue this workflow:\n",
        "\n",
        "*   **Visualization:** While the model is training, we would typically use **TensorBoard** to visualize the accuracy and spot problems, acting as a dashboard to see the model's mind at work.\n",
        "*   **Deployment:** Once training is complete, the model would be optimized using **TensorFlow Lite (TFLite)**. TFLite specializes in making the powerful model super small and efficient so it can run on edge devices like smartphones or smart home gadgets, allowing the AI to run right on the device for speed and privacy.\n",
        "\n",
        "The Keras workflow—defining layers, compiling, and calling `fit`—is like using **Lego bricks** to build a structure. The Lego bricks are the layers (Input, Embedding, Dense), and the compiled model is the instruction manual telling the structure how to stand up and function (the optimizer and loss function). When you call `fit`, you are simply starting the building process with the training data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}